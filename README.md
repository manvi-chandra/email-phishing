# email-phishing
To run your "Intelligent Phishing Email Detection System" application, you'll need to set up your Python environment, install the necessary libraries, and ensure you have the trained machine learning models.Step 1: Save the Application FileSave the Python code you provided as web_phishing_app.py.Step 2: Create and Train the Machine Learning ModelsYour application relies on two pre-trained files: tfidf_vectorizer.pkl and phishing_model.pkl. These files are generated by a training script. Below is a sample train_models.py script that you can use to create these files.train_models.pyimport pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
import joblib
import re
import string
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import os

# Download NLTK data if not already present
try:
    nltk.data.find('corpora/stopwords')
except (LookupError, Exception):
    nltk.download('stopwords', quiet=True)

try:
    nltk.data.find('corpora/wordnet')
except (LookupError, Exception):
    nltk.download('wordnet', quiet=True)

# Preprocessing functions (copied from your app for consistency)
def clean_text(text):
    if not isinstance(text, str):
        return ""
    text = re.sub(r'<.*?>', '', text)
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    text = text.lower()
    text = text.translate(str.maketrans('', '', string.punctuation))
    return text

def tokenize_and_lemmatize(text):
    lemmatizer = WordNetLemmatizer()
    stop_words = set(stopwords.words('english'))
    tokens = text.split()
    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]
    return " ".join(lemmatized_tokens)

def preprocess_email(email_content):
    cleaned = clean_text(email_content)
    processed = tokenize_and_lemmatize(cleaned)
    return processed

def generate_dummy_data(num_samples=1000):
    """Generates dummy email data for demonstration."""
    data = []
    # Legitimate examples (label 0)
    for _ in range(num_samples // 2):
        data.append({
            'text': f"Hello, your order {os.urandom(4).hex()} has been shipped. Track it here: yourlegitstore.com/track",
            'label': 0
        })
        data.append({
            'text': f"Meeting reminder for tomorrow at 10 AM. Agenda attached. Regards, Team.",
            'label': 0
        })
    # Phishing examples (label 1)
    for _ in range(num_samples // 2):
        data.append({
            'text': f"Urgent: Your account {os.urandom(4).hex()} has been suspended. Verify now: bit.ly/maliciouslink",
            'label': 1
        })
        data.append({
            'text': f"Security Alert! We detected unusual activity. Click to update your info: fakebank.com/login",
            'label': 1
        })
    return pd.DataFrame(data)

def train_and_save_models():
    print("Generating dummy data...")
    # For a real application, load your actual dataset here (e.g., from a CSV)
    # df = pd.read_csv('your_email_dataset.csv')
    # Make sure your dataset has 'text' and 'label' columns
    df = generate_dummy_data(num_samples=2000) # Generate more data for better training

    print("Preprocessing email content...")
    df['processed_text'] = df['text'].apply(preprocess_email)

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        df['processed_text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']
    )

    print("Training TF-IDF Vectorizer...")
    tfidf_vectorizer = TfidfVectorizer(max_features=5000) # Limit features for simplicity
    X_train_vectorized = tfidf_vectorizer.fit_transform(X_train)
    X_test_vectorized = tfidf_vectorizer.transform(X_test)

    print("Training Logistic Regression Model...")
    # Using Logistic Regression as it provides predict_proba
    model = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)
    model.fit(X_train_vectorized, y_train)

    print("Evaluating model...")
    y_pred = model.predict(X_test_vectorized)
    print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
    print("Classification Report:\n", classification_report(y_test, y_pred))

    # Save the vectorizer and model
    vectorizer_path = 'tfidf_vectorizer.pkl'
    model_path = 'phishing_model.pkl'

    print(f"Saving TF-IDF vectorizer to {vectorizer_path}...")
    joblib.dump(tfidf_vectorizer, vectorizer_path)
    print(f"Saving ML model to {model_path}...")
    joblib.dump(model, model_path)

    print("\nTraining complete. Model files generated.")

if __name__ == "__main__":
    train_and_save_models()
Save this code as train_models.py in the same directory as web_phishing_app.py.Step 3: Install DependenciesYou'll need streamlit, joblib, scikit-learn, and nltk.Open your terminal or command prompt.Navigate to the directory where you saved your Python files:cd /path/to/your/app_directory
Install the required libraries:pip install streamlit joblib scikit-learn pandas
(Note: nltk is handled by nltk.download calls within the script, but pandas is needed for train_models.py.)Step 4: Run the Training ScriptBefore running the main application, you need to generate the .pkl files.In your terminal, from the same directory, run:python train_models.py
This script will:Download necessary NLTK data (stopwords, wordnet).Generate a dummy dataset (for a real application, you'd load your own data).Preprocess the text.Train a TF-IDF vectorizer and a Logistic Regression model.Save tfidf_vectorizer.pkl and phishing_model.pkl in the same directory.Step 5: Run the Streamlit ApplicationOnce the .pkl files are generated:In your terminal, from the same directory, run the Streamlit application:streamlit run web_phishing_app.py
Streamlit will open a new tab in your web browser with the application. If it doesn't open automatically, it will provide a local URL (e.g., http://localhost:8501) that you can copy and paste into your browser.Now you should be able to interact with your Phishing Email Detection System!
